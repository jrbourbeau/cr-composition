{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='top'> </a>\n",
    "Author: [James Bourbeau](http://www.jamesbourbeau.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last updated: 2017-02-14 \n",
      "\n",
      "CPython 2.7.10\n",
      "IPython 5.2.2\n",
      "\n",
      "numpy 1.12.0\n",
      "matplotlib 2.0.0\n",
      "scipy 0.18.1\n",
      "pandas 0.19.2\n",
      "sklearn 0.18\n",
      "mlxtend 0.5.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -u -d -v -p numpy,matplotlib,scipy,pandas,sklearn,mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Cosmic-ray composition clustering\n",
    "### Table of contents\n",
    "1. [Define analysis free parameters](#Define-analysis-free-parameters)\n",
    "1. [Data preprocessing](#Data-preprocessing)\n",
    "2. [Fitting random forest](#Fit-random-forest-and-run-10-fold-CV-validation)\n",
    "3. [Fraction correctly identified](#Fraction-correctly-identified)\n",
    "4. [Spectrum](#Spectrum)\n",
    "5. [Unfolding](#Unfolding)\n",
    "6. [Feature importance](#Feature-importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to PYTHONPATH\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jbourbeau/cr-composition')\n",
    "print('Added to PYTHONPATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division, print_function\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import numpy as np\n",
    "from scipy import interp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit, KFold, StratifiedKFold\n",
    "from sklearn.cluster import KMeans\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "import composition as comp\n",
    "import composition.analysis.plotting as plotting\n",
    "    \n",
    "color_dict = {'light': 'C0', 'heavy': 'C1', 'total': 'C2',\n",
    "             'P': 'C0', 'He': 'C1', 'O': 'C3', 'Fe':'C4'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Define analysis free parameters\n",
    "[ [back to top](#top) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Whether or not to train on 'light' and 'heavy' composition classes, or the individual compositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "comp_class = True\n",
    "comp_list = ['light', 'heavy'] if comp_class else ['P', 'He', 'O', 'Fe']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Get composition classifier pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pipeline_str = 'xgboost'\n",
    "pipeline = comp.get_pipeline(pipeline_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Define energy binning for this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "energybins = comp.analysis.get_energybins()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data preprocessing\n",
    "[ [back to top](#top) ]\n",
    "1. Load simulation/data dataframe and apply specified quality cuts\n",
    "2. Extract desired features from dataframe\n",
    "3. Get separate testing and training datasets\n",
    "4. Feature transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim quality cut event flow:\n",
      "             IceTopQualityCuts:    1.0    1.0\n",
      "         lap_InIce_containment:  0.776  0.776\n",
      "             reco_energy_range:  0.654  0.493\n",
      "                 num_hits_1_30:  0.996  0.493\n",
      "                max_qfrac_1_30:  0.998  0.493\n",
      "              InIceQualityCuts:  0.784  0.486\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbourbeau/cr-composition/composition/dataframe_functions.py:124: RuntimeWarning: divide by zero encountered in log10\n",
      "  df['log_NChannels_'+i] = np.log10(df['NChannels_'+i])\n",
      "/home/jbourbeau/cr-composition/composition/dataframe_functions.py:125: RuntimeWarning: divide by zero encountered in log10\n",
      "  df['log_NHits_'+i] = np.log10(df['NHits_'+i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting the following features:\n",
      "\t$\\cos(\\theta_{\\mathrm{Lap}})$\n",
      "\t$\\log_{10}(S_{\\mathrm{125}})$\n",
      "\t$\\log_{10}(InIce charge (top 50))$\n",
      "\tCharge/NChannels\n",
      "\tNHits/NChannels\n",
      "\tdE/dX (standard)\n",
      "\t\n",
      "Number training events = 134262\n",
      "Number testing events = 57541\n"
     ]
    }
   ],
   "source": [
    "sim_train, sim_test = comp.preprocess_sim(comp_class=comp_class, return_energy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data quality cut event flow:\n",
      "             IceTopQualityCuts:    1.0    1.0\n",
      "         lap_InIce_containment:    1.0    1.0\n",
      "             reco_energy_range:    1.0    1.0\n",
      "                 num_hits_1_30:    1.0    1.0\n",
      "                max_qfrac_1_30:    1.0    1.0\n",
      "              InIceQualityCuts:  0.957  0.957\n",
      "\n",
      "\n",
      "Selecting the following features:\n",
      "\t$\\cos(\\theta_{\\mathrm{Lap}})$\n",
      "\t$\\log_{10}(S_{\\mathrm{125}})$\n",
      "\t$\\log_{10}(InIce charge (top 50))$\n",
      "\tCharge/NChannels\n",
      "\tNHits/NChannels\n",
      "\tdE/dX (standard)\n",
      "\t\n",
      "Number testing events = 2124113\n"
     ]
    }
   ],
   "source": [
    "data = comp.preprocess_data(comp_class=comp_class, return_energy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Run classifier over training and testing sets to get an idea of the degree of overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "XGBClassifier\n",
      "Training accuracy = 78.01%\n",
      "Testing accuracy = 77.66%\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "clf_name = pipeline.named_steps['classifier'].__class__.__name__\n",
    "print('=' * 30)\n",
    "print(clf_name)\n",
    "pipeline.fit(sim_train.X, sim_train.y)\n",
    "train_pred = pipeline.predict(sim_train.X)\n",
    "train_acc = accuracy_score(sim_train.y, train_pred)\n",
    "print('Training accuracy = {:.2%}'.format(train_acc))\n",
    "test_pred = pipeline.predict(sim_test.X)\n",
    "test_acc = accuracy_score(sim_test.y, test_pred)\n",
    "print('Testing accuracy = {:.2%}'.format(test_acc))\n",
    "# scores = cross_val_score(\n",
    "#     estimator=pipeline, X=sim_train.X, y=sim_train.y, cv=3, n_jobs=10)\n",
    "# print('CV score: {:.2%} (+/- {:.2%})'.format(scores.mean(), scores.std()))\n",
    "print('=' * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splitter = ShuffleSplit(n_splits=1, test_size=.5, random_state=2)\n",
    "for set1_index, set2_index in splitter.split(sim_train.X):\n",
    "    sim_train1 = sim_train[set1_index]\n",
    "    sim_train2 = sim_train[set2_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = kmeans.fit_predict(sim_train.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'heavy': array([False, False,  True, ..., False, False,  True], dtype=bool),\n",
       " 'light': array([ True,  True, False, ...,  True,  True, False], dtype=bool)}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MC_comp_mask = {}\n",
    "for composition in comp_list:\n",
    "    MC_comp_mask[composition] = sim_train.le.inverse_transform(sim_train.y) == composition\n",
    "MC_comp_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent light cluster in 0 = 0.209510965169\n",
      "percent light cluster in 1 = 0.712721355694\n"
     ]
    }
   ],
   "source": [
    "light_0 = np.sum(pred[MC_comp_mask['light']] == 0)/np.sum(MC_comp_mask['light'])\n",
    "light_1 = np.sum(pred[MC_comp_mask['light']] == 1)/np.sum(MC_comp_mask['light'])\n",
    "print('percent light cluster in 0 = {}'.format(light_0))\n",
    "print('percent light cluster in 1 = {}'.format(light_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent heavy cluster in 0 = 0.247993822487\n",
      "percent heavy cluster in 1 = 0.533506949702\n"
     ]
    }
   ],
   "source": [
    "heavy_0 = np.sum(pred[MC_comp_mask['heavy']] == 0)/np.sum(MC_comp_mask['heavy'])\n",
    "heavy_1 = np.sum(pred[MC_comp_mask['heavy']] == 1)/np.sum(MC_comp_mask['heavy'])\n",
    "print('percent heavy cluster in 0 = {}'.format(heavy_0))\n",
    "print('percent heavy cluster in 1 = {}'.format(heavy_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
